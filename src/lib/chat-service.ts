import OpenAI from 'openai';
import { Pinecone } from '@pinecone-database/pinecone';
import { openai } from './openai-config';

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

export interface Product {
  id: string;
  nome: string;
  descricao: string;
  valor: number;
  categoria: string;
  ingredientes: string[];
  adicionais: string[];
  imagem: string;
  codigo: string;
  ativado: boolean;
  promocional: boolean;
  textoEmbedding: number[] | null;
}

// Configura√ß√£o do Pinecone
const pinecone = new Pinecone({
  apiKey: process.env.PINECONE_API_KEY!,
});

const index = pinecone.index('gelaboca');

// Fun√ß√£o para gerar embedding usando OpenAI
async function generateEmbedding(text: string): Promise<number[]> {
  try {
    const response = await openai.embeddings.create({
      model: 'text-embedding-3-large',
      input: text,
      dimensions: 3072 // Dimens√£o do Pinecone
    });

    return response.data[0].embedding;
  } catch (error) {
    console.error('Erro ao gerar embedding:', error);
    throw error;
  }
}

// Fun√ß√£o para calcular similaridade de cosseno
function cosineSimilarity(vecA: number[], vecB: number[]): number {
  const dotProduct = vecA.reduce((sum, a, i) => sum + a * vecB[i], 0);
  const normA = Math.sqrt(vecA.reduce((sum, a) => sum + a * a, 0));
  const normB = Math.sqrt(vecB.reduce((sum, b) => sum + b * b, 0));
  return dotProduct / (normA * normB);
}

// Est√°gio 1: Ajustar e contextualizar a mensagem do usu√°rio
async function adjustUserMessage(userMessage: string, conversationHistory: ChatMessage[]): Promise<string> {
  const systemPrompt = `Voc√™ √© o GelinhIA, assistente virtual da sorveteria GelaBoca. 
  
Sua fun√ß√£o √© ajustar e contextualizar as mensagens dos usu√°rios para torn√°-las mais completas e diretas, facilitando a busca por produtos.

Analise a mensagem do usu√°rio e todo o contexto da conversa, e retorne uma vers√£o ajustada que seja:
- Mais espec√≠fica sobre o que o usu√°rio quer
- Inclua informa√ß√µes relevantes do contexto da conversa
- Seja direta e clara sobre a inten√ß√£o
- Mantenha a ess√™ncia da solicita√ß√£o original

Retorne APENAS a mensagem ajustada, sem explica√ß√µes adicionais.`;

  const conversationContext = conversationHistory
    .map(msg => `${msg.role}: ${msg.content}`)
    .join('\n');

  const prompt = `${systemPrompt}

Hist√≥rico da conversa:
${conversationContext}

Mensagem atual do usu√°rio: "${userMessage}"

Mensagem ajustada:`;

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 200,
      temperature: 0.3
    });

    return response.choices[0]?.message?.content?.trim() || userMessage;
  } catch (error) {
    console.error('Erro ao ajustar mensagem:', error);
    return userMessage; // Fallback para mensagem original
  }
}

// Est√°gio 2: Buscar produtos por similaridade no Pinecone
async function findSimilarProducts(adjustedMessage: string): Promise<Product[]> {
  try {
    // Gerar embedding da mensagem ajustada
    const messageEmbedding = await generateEmbedding(adjustedMessage);
    
    // Buscar produtos similares no Pinecone
    const queryResponse = await index.query({
      vector: messageEmbedding,
      topK: 8,
      includeMetadata: true,
      filter: {
        ativado: { $eq: true } // Apenas produtos ativados
      }
    });

    // Converter resultados para interface Product
    const products: Product[] = queryResponse.matches
      .filter(match => match.metadata)
      .map(match => {
        const textoEmbedding = match.metadata?.textoEmbedding;
        let embeddingArray: number[] | null = null;
        
        if (Array.isArray(textoEmbedding)) {
          embeddingArray = textoEmbedding.every(item => typeof item === 'number') 
            ? textoEmbedding as number[] 
            : null;
        }

        return {
          id: match.id,
          nome: match.metadata?.nome as string,
          descricao: match.metadata?.descricao as string,
          valor: Number(match.metadata?.valor),
          categoria: match.metadata?.categoria as string,
          ingredientes: match.metadata?.ingredientes as string[] || [],
          adicionais: match.metadata?.adicionais as string[] || [],
          imagem: match.metadata?.imagem as string,
          codigo: match.metadata?.codigo as string,
          ativado: Boolean(match.metadata?.ativado),
          promocional: Boolean(match.metadata?.promocional),
          textoEmbedding: embeddingArray
        };
      });

    console.log(`Encontrados ${products.length} produtos similares no Pinecone`);
    console.log('üìã Produtos encontrados:', products.map(p => p.nome).join(', '));
    return products;
  } catch (error) {
    console.error('Erro ao buscar produtos similares no Pinecone:', error);
    
    // Fallback: buscar todos os produtos ativados
    try {
      const fallbackResponse = await index.query({
        vector: new Array(3072).fill(0), // Vector dummy
        topK: 8,
        includeMetadata: true,
        filter: {
          ativado: { $eq: true }
        }
      });

      const fallbackProducts: Product[] = fallbackResponse.matches
        .filter(match => match.metadata)
        .map(match => ({
          id: match.id,
          nome: match.metadata?.nome as string,
          descricao: match.metadata?.descricao as string,
          valor: Number(match.metadata?.valor),
          categoria: match.metadata?.categoria as string,
          ingredientes: match.metadata?.ingredientes as string[] || [],
          adicionais: match.metadata?.adicionais as string[] || [],
          imagem: match.metadata?.imagem as string,
          codigo: match.metadata?.codigo as string,
          ativado: Boolean(match.metadata?.ativado),
          promocional: Boolean(match.metadata?.promocional),
          textoEmbedding: null
        }));

             console.log(`Fallback: Encontrados ${fallbackProducts.length} produtos ativados`);
       console.log('üìã Produtos fallback:', fallbackProducts.map(p => p.nome).join(', '));
       return fallbackProducts.slice(0, 8);
    } catch (fallbackError) {
      console.error('Erro no fallback de busca:', fallbackError);
      return []; // Retornar array vazio se tudo falhar
    }
  }
}

// Est√°gio 3: Selecionar o produto mais adequado
async function selectBestProduct(
  userMessage: string, 
  conversationHistory: ChatMessage[], 
  similarProducts: Product[]
): Promise<Product | null> {
  if (similarProducts.length === 0) {
    return null;
  }

  const systemPrompt = `Voc√™ √© o GelinhIA, assistente virtual da sorveteria GelaBoca.

Analise a mensagem do usu√°rio, o hist√≥rico da conversa e a lista de produtos similares fornecida.
Selecione o produto que MELHOR atende √† solicita√ß√£o do usu√°rio.

REGRAS IMPORTANTES:
1. Se o usu√°rio menciona qualquer produto, sabor, ou demonstra interesse em comprar/experimentar algo, SEMPRE selecione um produto da lista
2. Se o usu√°rio pergunta "voc√™ tem", "quero", "gostaria de", "tem algum", etc., SEMPRE selecione um produto
3. S√≥ retorne "NENHUM" se a solicita√ß√£o for sobre hor√°rios, localiza√ß√£o, pagamento, ou outros assuntos N√ÉO relacionados a produtos

EXEMPLOS:
- "quero um sorvete" ‚Üí selecione um sorvete
- "tem chocolate?" ‚Üí selecione produto com chocolate
- "qual hor√°rio voc√™s abrem?" ‚Üí retorne "NENHUM"

Retorne APENAS o ID completo do produto escolhido ou "NENHUM".`;

  const conversationContext = conversationHistory
    .map(msg => `${msg.role}: ${msg.content}`)
    .join('\n');

  const productsList = similarProducts
    .map(p => `ID: ${p.id} - ${p.nome}: ${p.descricao} (R$ ${p.valor.toFixed(2)})`)
    .join('\n');

  const prompt = `${systemPrompt}

Hist√≥rico da conversa:
${conversationContext}

Mensagem atual: "${userMessage}"

Produtos similares dispon√≠veis:
${productsList}

ID do produto escolhido:`;

  try {
    console.log('üéØ Prompt enviado para sele√ß√£o:', prompt);
    
    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 50, // Aumentado para n√£o cortar o ID
      temperature: 0.1
    });

    const selectedId = response.choices[0]?.message?.content?.trim();
    console.log('üéØ Resposta do GPT para sele√ß√£o:', selectedId);
    
    if (selectedId === 'NENHUM' || !selectedId) {
      console.log('üéØ Nenhum produto selecionado pelo GPT');
      return null;
    }

    // Buscar produto por ID exato primeiro
    let selectedProduct = similarProducts.find(p => p.id === selectedId);
    
    // Se n√£o encontrou, tentar buscar por ID parcial (caso tenha sido cortado)
    if (!selectedProduct && selectedId && selectedId !== 'NENHUM') {
      selectedProduct = similarProducts.find(p => p.id.startsWith(selectedId));
      console.log('üéØ Tentando busca parcial com:', selectedId);
    }
    
    console.log('üéØ Produto encontrado por ID:', selectedProduct?.nome || 'N√£o encontrado');
    return selectedProduct || null;
  } catch (error) {
    console.error('Erro ao selecionar produto:', error);
    return similarProducts[0] || null; // Fallback para primeiro produto
  }
}

// Est√°gio 4: Gerar resposta baseada no produto selecionado
async function generateProductResponse(
  userMessage: string,
  conversationHistory: ChatMessage[],
  selectedProduct: Product
): Promise<string> {
  const systemPrompt = `Voc√™ √© o GelinhIA, assistente virtual da sorveteria GelaBoca.

Voc√™ deve responder de forma BREVE, DIRETA e AMIG√ÅVEL sobre o produto selecionado.
Sua resposta deve:
- Ser concisa (m√°ximo 2-3 frases)
- Incluir pre√ßo e destaque principal do produto
- Manter tom entusiasmado mas direto
- Usar 1-2 emojis no m√°ximo

Exemplo de resposta ideal:
"Ah, o Gela Cone Crocante √© uma del√≠cia! üòã Custa R$ 20,00 e combina sorvete cremoso com casquinha crocante. Posso te ajudar com mais alguma coisa?"

Seja direto e resolva a d√∫vida do usu√°rio rapidamente.`;

  const conversationContext = conversationHistory
    .map(msg => `${msg.role}: ${msg.content}`)
    .join('\n');

  const productInfo = `
Produto: ${selectedProduct.nome}
Descri√ß√£o: ${selectedProduct.descricao}
Pre√ßo: R$ ${selectedProduct.valor.toFixed(2)}
Categoria: ${selectedProduct.categoria}
Ingredientes: ${selectedProduct.ingredientes.join(', ')}
Adicionais dispon√≠veis: ${selectedProduct.adicionais.join(', ')}
`;

  const prompt = `${systemPrompt}

Hist√≥rico da conversa:
${conversationContext}

Mensagem do usu√°rio: "${userMessage}"

Informa√ß√µes do produto selecionado:
${productInfo}

Resposta do GelinhIA:`;

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 150, // Reduzido para respostas mais breves
      temperature: 0.7
    });

    return response.choices[0]?.message?.content?.trim() || 
           `Ah, o ${selectedProduct.nome} √© uma del√≠cia! üòã Custa R$ ${selectedProduct.valor.toFixed(2)}. Posso te ajudar com mais alguma coisa?`;
  } catch (error) {
    console.error('Erro ao gerar resposta:', error);
    return `Que legal! O ${selectedProduct.nome} √© uma excelente op√ß√£o! üòä Custa R$ ${selectedProduct.valor.toFixed(2)}. Posso te ajudar com mais alguma coisa?`;
  }
}

// Fun√ß√£o principal que orquestra todos os est√°gios
export async function processChatMessage(
  userMessage: string,
  conversationHistory: ChatMessage[]
): Promise<{ message: string; productInfo?: { name: string; slug: string } }> {
  try {
    console.log('üîÑ Processando mensagem:', userMessage);

    // Est√°gio 1: Ajustar mensagem do usu√°rio
    console.log('üìù Est√°gio 1: Ajustando mensagem...');
    const adjustedMessage = await adjustUserMessage(userMessage, conversationHistory);
    console.log('‚úÖ Mensagem ajustada:', adjustedMessage);

    // Est√°gio 2: Buscar produtos similares no Pinecone
    console.log('üîç Est√°gio 2: Buscando produtos similares no Pinecone...');
    const similarProducts = await findSimilarProducts(adjustedMessage);
    console.log('‚úÖ Produtos encontrados:', similarProducts.length);

    // Est√°gio 3: Selecionar melhor produto
    console.log('üéØ Est√°gio 3: Selecionando melhor produto...');
    const selectedProduct = await selectBestProduct(userMessage, conversationHistory, similarProducts);
    console.log('‚úÖ Produto selecionado:', selectedProduct?.nome || 'Nenhum');

    // Est√°gio 4: Gerar resposta
    console.log('üí¨ Est√°gio 4: Gerando resposta...');
    let response: string;

    if (selectedProduct) {
      response = await generateProductResponse(userMessage, conversationHistory, selectedProduct);
    } else {
      // Resposta gen√©rica quando nenhum produto √© selecionado
      response = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: `Voc√™ √© o GelinhIA, assistente virtual da sorveteria GelaBoca. 
            Responda de forma amig√°vel e ajude o cliente com informa√ß√µes sobre a sorveteria, 
            hor√°rios, localiza√ß√£o, ou qualquer outra d√∫vida. Seja sempre simp√°tico e prestativo.`
          },
          { role: 'user', content: userMessage }
        ],
        max_tokens: 200,
        temperature: 0.7
      }).then(res => res.choices[0]?.message?.content?.trim() || 
        'Ol√°! Sou o GelinhIA, seu assistente virtual da GelaBoca! üòä Como posso te ajudar hoje?');
    }

    console.log('‚úÖ Resposta gerada com sucesso!');
    
    // Se um produto foi selecionado, retornar informa√ß√µes dele
    if (selectedProduct) {
      return {
        message: response,
        productInfo: {
          name: selectedProduct.nome,
          slug: selectedProduct.nome // Usar o nome original para a URL
        }
      };
    }
    
    return { message: response };

  } catch (error) {
    console.error('‚ùå Erro no processamento da mensagem:', error);
    return { message: 'Desculpe, tive um probleminha t√©cnico aqui! üòÖ Pode tentar novamente? Estou aqui para te ajudar!' };
  }
} 